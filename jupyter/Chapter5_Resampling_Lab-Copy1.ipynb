{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resamping method\n",
    "### Validation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(ISLR)\n",
    "set.seed(1)\n",
    "train=sample(392, 196)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the `sample()` function to split the set of observations\n",
    "into two halves, by selecting a random subset of 196 observations out of the original 392 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "196"
      ],
      "text/latex": [
       "196"
      ],
      "text/markdown": [
       "196"
      ],
      "text/plain": [
       "[1] 196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "length(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm.fit = lm(mpg ~ horsepower, data = Auto, subset=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "attach(Auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "26.1414211520072"
      ],
      "text/latex": [
       "26.1414211520072"
      ],
      "text/markdown": [
       "26.1414211520072"
      ],
      "text/plain": [
       "[1] 26.14142"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean( (mpg - predict(lm.fit, Auto))[-train]^2) # MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the estimated test MSE for the linear regression fit is 26.14. We can use the `poly()` function to estimate the test error for the polynomial and cubic regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.8225850408262"
      ],
      "text/latex": [
       "19.8225850408262"
      ],
      "text/markdown": [
       "19.8225850408262"
      ],
      "text/plain": [
       "[1] 19.82259"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit2 = lm(mpg ~ poly(horsepower, 2), data=Auto, subset=train)\n",
    "mean( (mpg - predict(lm.fit2, Auto))[-train]^2) # MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.7825166856023"
      ],
      "text/latex": [
       "19.7825166856023"
      ],
      "text/markdown": [
       "19.7825166856023"
      ],
      "text/plain": [
       "[1] 19.78252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit2 = lm(mpg ~ poly(horsepower, 3), data=Auto, subset=train)\n",
    "mean( (mpg - predict(lm.fit2, Auto))[-train]^2) # MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These error rates are 19.82 and 19.78, respectively. If we choose a different training set instead, then we will obtain somewhat different errors on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "23.2955851508862"
      ],
      "text/latex": [
       "23.2955851508862"
      ],
      "text/markdown": [
       "23.2955851508862"
      ],
      "text/plain": [
       "[1] 23.29559"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(2)\n",
    "train = sample(392, 196)\n",
    "lm.fit = lm(mpg ~ horsepower, data = Auto, subset=train)\n",
    "mean( (mpg - predict(lm.fit, Auto))[-train]^2) # MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "18.9012408317778"
      ],
      "text/latex": [
       "18.9012408317778"
      ],
      "text/markdown": [
       "18.9012408317778"
      ],
      "text/plain": [
       "[1] 18.90124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit2 = lm(mpg ~ poly(horsepower, 2), data=Auto, subset=train)\n",
    "mean( (mpg - predict(lm.fit2, Auto))[-train]^2) # MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "19.2573982608642"
      ],
      "text/latex": [
       "19.2573982608642"
      ],
      "text/markdown": [
       "19.2573982608642"
      ],
      "text/plain": [
       "[1] 19.2574"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit2 = lm(mpg ~ poly(horsepower, 3), data=Auto, subset=train)\n",
    "mean( (mpg - predict(lm.fit2, Auto))[-train]^2) # MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LOOCV estimate can be automatically computed for any generalized linear model using the <span style=\"color:blue\">glm()</span> and <span style=\"color:blue\">cv.glm()</span> functions. In the lab for Chap- ter 4, we used the glm() function to perform logistic regression by passing in the family=\"binomial\" argument. But if we use glm() to fit a model without passing in the family argument, then it performs linear regression, just like the lm() function. So for instance,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>39.9358610211705</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.157844733353654</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glm.fit = glm(mpg~horsepower, data=Auto)\n",
    "coef(glm.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>39.9358610211705</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.157844733353654</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm.fit = lm(mpg~horsepower, data=Auto)\n",
    "coef(lm.fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yield identical linear regression models. In this lab, we will perform linear regression using the glm() function rather than the lm() function because the latter can be used together with cv.glm(). The cv.glm() function is part of the boot library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2315135179292</li>\n",
       "\t<li>24.2311440937562</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 24.2311440937562\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 24.2311440937562\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 24.23114"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(boot)\n",
    "glm.fit = glm(mpg~horsepower, data=Auto)\n",
    "cv.err=cv.glm(Auto,glm.fit)\n",
    "cv.err$delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Length Class  Mode   \n",
       "call    3    -none- call   \n",
       "K       1    -none- numeric\n",
       "delta   2    -none- numeric\n",
       "seed  626    -none- numeric"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(cv.err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2315135179292</li>\n",
       "\t<li>19.2482131244897</li>\n",
       "\t<li>19.334984064029</li>\n",
       "\t<li>19.4244303104303</li>\n",
       "\t<li>19.0332138547041</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2315135179292\n",
       "\\item 19.2482131244897\n",
       "\\item 19.334984064029\n",
       "\\item 19.4244303104303\n",
       "\\item 19.0332138547041\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2315135179292\n",
       "2. 19.2482131244897\n",
       "3. 19.334984064029\n",
       "4. 19.4244303104303\n",
       "5. 19.0332138547041\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 24.23151 19.24821 19.33498 19.42443 19.03321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv.error = rep(0, 5)\n",
    "for (i in 1:5){\n",
    "    glm.fit = glm(mpg~poly(horsepower, i), data=Auto)\n",
    "    cv.error[i] = cv.glm(Auto, glm.fit)$delta[1]\n",
    "}\n",
    "cv.error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Fold cross validaton\n",
    "The cv.glm() function can also be used to implement k-fold CV. Below we use k = 10, a common choice for k, on the Auto data set. We once again set a random seed and initialize a vector in which we will store the CV errors corresponding to the polynomial fits of orders one to ten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>24.2051967567753</li>\n",
       "\t<li>19.1892390663471</li>\n",
       "\t<li>19.3066158967501</li>\n",
       "\t<li>19.3379909004929</li>\n",
       "\t<li>18.8791148363354</li>\n",
       "\t<li>19.0210341885228</li>\n",
       "\t<li>18.8960903802809</li>\n",
       "\t<li>19.7120146188182</li>\n",
       "\t<li>18.9514005667302</li>\n",
       "\t<li>19.501959228555</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 24.2051967567753\n",
       "\\item 19.1892390663471\n",
       "\\item 19.3066158967501\n",
       "\\item 19.3379909004929\n",
       "\\item 18.8791148363354\n",
       "\\item 19.0210341885228\n",
       "\\item 18.8960903802809\n",
       "\\item 19.7120146188182\n",
       "\\item 18.9514005667302\n",
       "\\item 19.501959228555\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 24.2051967567753\n",
       "2. 19.1892390663471\n",
       "3. 19.3066158967501\n",
       "4. 19.3379909004929\n",
       "5. 18.8791148363354\n",
       "6. 19.0210341885228\n",
       "7. 18.8960903802809\n",
       "8. 19.7120146188182\n",
       "9. 18.9514005667302\n",
       "10. 19.501959228555\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] 24.20520 19.18924 19.30662 19.33799 18.87911 19.02103 18.89609 19.71201\n",
       " [9] 18.95140 19.50196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(17)\n",
    "cv.error.10 = rep(0, 10)\n",
    "for (i in 1:10){\n",
    "    glm.fit = glm(mpg~poly(horsepower, i), data=Auto)\n",
    "    cv.error.10[i] = cv.glm(Auto, glm.fit, K=10)$delta[1]\n",
    "}\n",
    "cv.error.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The bootstrap\n",
    "#### Estimating the accuracy of a statistic of Interest\n",
    "One of the great advantages of the bootstrap approach is that it can be applied in almost all situations. No complicated mathematical calculations are required. Performing a bootstrap analysis in R entails only two steps. First, we must create a function that computes the statistic of interest. Second, we use the <span style=\"color:blue\">boot()</span> function, which is part of the boot library, to perform the bootstrap by repeatedly sampling observations from the data set with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha.fn = function(data, index) {\n",
    "    X = data$X[index]\n",
    "    Y = data$Y[index]\n",
    "    return((var(Y)-cov(X,Y))/(var(X)+var(Y)-2*cov(X,Y)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.57583207459283"
      ],
      "text/latex": [
       "0.57583207459283"
      ],
      "text/markdown": [
       "0.57583207459283"
      ],
      "text/plain": [
       "[1] 0.5758321"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha.fn(Portfolio ,1:100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X</th><th scope=col>Y</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.8952509</td><td>-0.2349235</td></tr>\n",
       "\t<tr><td>-1.5624543</td><td>-0.8851760</td></tr>\n",
       "\t<tr><td>-0.4170899</td><td> 0.2718880</td></tr>\n",
       "\t<tr><td> 1.0443557</td><td>-0.7341975</td></tr>\n",
       "\t<tr><td>-0.3155684</td><td> 0.8419834</td></tr>\n",
       "\t<tr><td>-1.7371238</td><td>-2.0371910</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " X & Y\\\\\n",
       "\\hline\n",
       "\t -0.8952509 & -0.2349235\\\\\n",
       "\t -1.5624543 & -0.8851760\\\\\n",
       "\t -0.4170899 &  0.2718880\\\\\n",
       "\t  1.0443557 & -0.7341975\\\\\n",
       "\t -0.3155684 &  0.8419834\\\\\n",
       "\t -1.7371238 & -2.0371910\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| X | Y |\n",
       "|---|---|\n",
       "| -0.8952509 | -0.2349235 |\n",
       "| -1.5624543 | -0.8851760 |\n",
       "| -0.4170899 |  0.2718880 |\n",
       "|  1.0443557 | -0.7341975 |\n",
       "| -0.3155684 |  0.8419834 |\n",
       "| -1.7371238 | -2.0371910 |\n",
       "\n"
      ],
      "text/plain": [
       "  X          Y         \n",
       "1 -0.8952509 -0.2349235\n",
       "2 -1.5624543 -0.8851760\n",
       "3 -0.4170899  0.2718880\n",
       "4  1.0443557 -0.7341975\n",
       "5 -0.3155684  0.8419834\n",
       "6 -1.7371238 -2.0371910"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next command uses the sample() function to randomly select 100 ob- servations from the range 1 to 100, with replacement. This is equivalent to constructing a new bootstrap data set and recomputing $\\hat{\\alpha}$ based on the new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.596383302006392"
      ],
      "text/latex": [
       "0.596383302006392"
      ],
      "text/markdown": [
       "0.596383302006392"
      ],
      "text/plain": [
       "[1] 0.5963833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(1)\n",
    "alpha.fn(Portfolio,sample(100,100,replace=T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " However, the boot() function automates boot() this approach. Below we produce R = 1, 000 bootstrap estimates for α."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Portfolio, statistic = alpha.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "     original        bias    std. error\n",
       "t1* 0.5758321 -7.315422e-05  0.08861826"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Portfolio ,alpha.fn,R=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating the accuracy of a Linear Regression Model\n",
    "The bootstrap approach can be used to assess the variability of the coef- ficient estimates and predictions from a statistical learning method. Here we use the bootstrap approach in order to assess the variability of the estimates for β0 and β1, the intercept and slope terms for the linear regres- sion model that uses horsepower to predict mpg in the Auto data set. We will compare the estimates obtained using the bootstrap to those obtained using the formulas for SE(βˆ0) and SE(βˆ1) described in Section 3.1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boot.fn = function(data, index){return(coef(lm(mpg~horsepower, data=Auto, subset=index)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>(Intercept)</dt>\n",
       "\t\t<dd>39.9358610211705</dd>\n",
       "\t<dt>horsepower</dt>\n",
       "\t\t<dd>-0.157844733353654</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[(Intercept)] 39.9358610211705\n",
       "\\item[horsepower] -0.157844733353654\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "(Intercept)\n",
       ":   39.9358610211705horsepower\n",
       ":   -0.157844733353654\n",
       "\n"
      ],
      "text/plain": [
       "(Intercept)  horsepower \n",
       " 39.9358610  -0.1578447 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot.fn(Auto, 1:392)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "ORDINARY NONPARAMETRIC BOOTSTRAP\n",
       "\n",
       "\n",
       "Call:\n",
       "boot(data = Auto, statistic = boot.fn, R = 1000)\n",
       "\n",
       "\n",
       "Bootstrap Statistics :\n",
       "      original        bias    std. error\n",
       "t1* 39.9358610  0.0126152644 0.871267432\n",
       "t2* -0.1578447 -0.0002691801 0.007540188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "boot(Auto, boot.fn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>39.9358610   </td><td>0.717498656  </td><td> 55.65984    </td><td>1.220362e-187</td></tr>\n",
       "\t<tr><th scope=row>horsepower</th><td>-0.1578447   </td><td>0.006445501  </td><td>-24.48914    </td><td> 7.031989e-81</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 39.9358610    & 0.717498656   &  55.65984     & 1.220362e-187\\\\\n",
       "\thorsepower & -0.1578447    & 0.006445501   & -24.48914     &  7.031989e-81\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(>|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | 39.9358610    | 0.717498656   |  55.65984     | 1.220362e-187 |\n",
       "| horsepower | -0.1578447    | 0.006445501   | -24.48914     |  7.031989e-81 |\n",
       "\n"
      ],
      "text/plain": [
       "            Estimate   Std. Error  t value   Pr(>|t|)     \n",
       "(Intercept) 39.9358610 0.717498656  55.65984 1.220362e-187\n",
       "horsepower  -0.1578447 0.006445501 -24.48914  7.031989e-81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(lm(mpg~horsepower, data=Auto))$coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
